{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D,GlobalAveragePooling2D,Dense,Conv2D, Convolution2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras import Input\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# import the Google AutoML client library\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "\n",
    "from google.cloud import storage\n",
    "import gc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list()\n",
    "data=list()\n",
    "def load_data(bucket_name):\n",
    "    \n",
    "    bucket = storage.Client().get_bucket(bucket_name)\n",
    "    for item in range(50):\n",
    "        path = 'Faces/Augmentation Data/Symptoms/'+str(item)+'_symptoms.jpg'\n",
    "        blob = bucket.get_blob(path)\n",
    "        img = np.array(cv2.imdecode(np.asarray(bytearray(blob.download_as_string()),dtype=np.uint8),3))\n",
    "        data.append(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "        labels.append(1)\n",
    "    for item in range(50):\n",
    "        path = 'Faces/Augmentation Data/Normal/'+str(item)+'_normal.jpg'\n",
    "        blob = bucket.get_blob(path)\n",
    "        img = np.array(cv2.imdecode(np.asarray(bytearray(blob.download_as_string()),dtype=np.uint8),3))\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        data.append(img)\n",
    "        labels.append(0)\n",
    "        \n",
    "    return np.asarray(data),np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(ori,flip,flip2):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Random Brightness')\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(ori.astype(np.uint8))\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Random Noise')\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(flip.astype(np.uint8))\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Random Hue')\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(flip2.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(data[5],data[6],data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(data,labels,test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,y_train,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train/255.\n",
    "X_test_cnn = X_test/255.\n",
    "X_valid_cnn = X_valid/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGGFace(weights='vggface',\n",
    "                        include_top=False,\n",
    "                        input_shape=(200,200,3))\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding=\"Same\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding=\"Same\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = model.fit(X_train_cnn, y_train, epochs=5, \n",
    "                  verbose=2, validation_data=(X_test_cnn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable AI Setup Google Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_baseline = np.random.rand(200,200,3)\n",
    "\n",
    "explanation_metadata = {\n",
    "    \"inputs\": {\n",
    "      \"data\": {\n",
    "        \"input_tensor_name\": \"vggface_vgg16_input:0\",\n",
    "        \"modality\": \"image\",\n",
    "        \"input_baselines\": [random_baseline.tolist()]\n",
    "      }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "      \"probability\": {\n",
    "        \"output_tensor_name\": \"dense_15/Softmax:0\"\n",
    "      }\n",
    "    },\n",
    "  \"framework\": \"tensorflow\"\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('explanation_metadata.json', 'w') as output_file:\n",
    "    json.dump(explanation_metadata, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp explanation_metadata.json $export_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = 'your_path'\n",
    "MODEL='face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform models create $MODEL --enable-logging --regions=us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_VERSION = 'v_ig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai-platform versions create $IG_VERSION \\\n",
    "--model $MODEL \\\n",
    "--origin $export_path \\\n",
    "--runtime-version 1.15 \\\n",
    "--framework TENSORFLOW \\\n",
    "--python-version 3.7 \\\n",
    "--machine-type n1-standard-4 \\\n",
    "--explanation-method integrated-gradients \\\n",
    "--num-integral-steps 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform versions describe $IG_VERSION --model $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances=list()\n",
    "data=list()\n",
    "def load_data(bucket_name):\n",
    "    \n",
    "    bucket = storage.Client().get_bucket(bucket_name)\n",
    "    for item in range(1):\n",
    "        path = 'Faces/Augmentation Data/Symptoms/'+str(item)+'_symptoms.jpg'\n",
    "        blob = bucket.get_blob(path)\n",
    "        img = np.array(cv2.imdecode(np.asarray(bytearray(blob.download_as_string()),dtype=np.uint8),3))\n",
    "        #data.append()\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        #img = base64.b64encode(img).decode('utf-8')\n",
    "        img = img.tolist()\n",
    "        instances.append({'conv2d_input': img})\n",
    "\n",
    "        \n",
    "    for item in range(1):\n",
    "        path = 'Faces/Augmentation Data/Normal/'+str(item)+'_normal.jpg'\n",
    "        blob = bucket.get_blob(path)\n",
    "        img = np.array(cv2.imdecode(np.asarray(bytearray(blob.download_as_string()),dtype=np.uint8),3))\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        #img = base64.b64encode(img).decode('utf-8')\n",
    "        img = img.tolist()\n",
    "        instances.append({'conv2d_input': img})\n",
    "        \n",
    "   \n",
    "        \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = load_data('bucket_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "bucket = storage.Client().get_bucket('bucket_name')\n",
    "path = 'ck.jpg'\n",
    "blob = bucket.get_blob(path)\n",
    "img = np.array(cv2.imdecode(np.asarray(bytearray(blob.download_as_string()),dtype=np.uint8),3))\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img = base64.b64encode(img).decode('utf-8')\n",
    "instances.append({'conv2d_input': [{'b64':img}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_json(project, model, instances, version=None):\n",
    "\n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().explain(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = []\n",
    "# path = 'faces2/symptoms/'+str(2593)+'_symptoms.jpg'\n",
    "# test_filenames.append(path)\n",
    "    \n",
    "\n",
    "# path = 'faces2/normal/'+str(2188)+'_normal.jpg'\n",
    "# test_filenames.append(path)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    \n",
    "    path = 'faces2/symptoms/'+str(i)+'_symptoms.jpg'\n",
    "    test_filenames.append(path)\n",
    "    \n",
    "    path = 'faces2/normal/'+str(i)+'_normal.jpg'\n",
    "    test_filenames.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "\n",
    "for i in test_filenames:\n",
    "    with open(i,'rb') as img:\n",
    "        b64str = base64.b64encode(img.read()).decode('utf-8')\n",
    "        instances.append({'conv2d_input': [{'b64':b64str}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_response = predict_json('ambient-depth-287712', MODEL, instances, IG_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "classes = {0:'normal',1:'symptoms'}\n",
    "# Note: change the `ig_response` variable below if you didn't deploy an IG model\n",
    "for i,val in enumerate(ig_response['explanations']):\n",
    "    class_name = classes[val['attributions_by_label'][0]['label_index']]\n",
    "    confidence_score = str(round(val['attributions_by_label'][0]['example_score'] * 100, 3)) + '%'\n",
    "    print('Predicted class: ' + str(class_name) + '\\n' + 'Confidence score: ' + confidence_score)\n",
    "    \n",
    "    img = instances[i]['conv2d_input'][0]['b64']\n",
    "    im = BytesIO(base64.b64decode(img))\n",
    "    i = mpimg.imread(im, format='JPG')\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "for idx, face in enumerate(ig_response['explanations']):\n",
    "    predicted_face = classes[face['attributions_by_label'][0]['label_index']]\n",
    "    confidence = face['attributions_by_label'][0]['example_score']\n",
    "    print('Predicted face: ', predicted_face)\n",
    "    b64str = face['attributions_by_label'][0]['attributions']['data']['b64_jpeg']\n",
    "    i = base64.b64decode(b64str)\n",
    "    i = io.BytesIO(i)\n",
    "    i = mpimg.imread(i, format='JPG')\n",
    "\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,val in enumerate(ig_response['explanations']):\n",
    "    baseline_score = val['attributions_by_label'][0]['baseline_score']\n",
    "    predicted_score = val['attributions_by_label'][0]['example_score']\n",
    "    print('Baseline score: ', baseline_score) \n",
    "    print('Predicted score: ', predicted_score)\n",
    "    print('Predicted - Baseline: ', predicted_score - baseline_score, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_img = PIL.Image.fromarray((random_baseline * 255).astype('uint8'))\n",
    "buffer = BytesIO()\n",
    "rand_test_img.save(buffer, format=\"BMP\")\n",
    "new_image_string = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Preview it\n",
    "plt.imshow(rand_test_img)\n",
    "# Save the image to a variable in the format our model is expecting\n",
    "sanity_check_img = {'conv2d_input': [{'b64': new_image_string}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_resp = predict_json('ambient-depth-287712', MODEL, sanity_check_img, IG_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_img = base64.b64decode(sanity_check_resp['explanations'][0]['attributions_by_label'][0]['attributions']['data']['b64_jpeg'])\n",
    "sanity_check_img = io.BytesIO(sanity_check_img)\n",
    "sanity_check_img = mpimg.imread(sanity_check_img, format='JPG')\n",
    "\n",
    "plt.imshow(sanity_check_img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score = sanity_check_resp['explanations'][0]['attributions_by_label'][0]['baseline_score']\n",
    "example_score = sanity_check_resp['explanations'][0]['attributions_by_label'][0]['example_score']\n",
    "\n",
    "print(abs(baseline_score - example_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_metadata = {\n",
    "    \"inputs\": {\n",
    "      \"data\": {\n",
    "        \"input_tensor_name\": \"vggface_vgg16_input:0\",\n",
    "        \"modality\": \"image\",\n",
    "        \"visualization\": {\n",
    "        \"type\": \"Pixels\", # Can also use \"pixels\"\n",
    "        \"polarity\": \"negative\",\n",
    "        \"clip_below_percentile\": 0,\n",
    "        \"clip_above_percentile\": 100,\n",
    "        \"color_map\": \"viridis\",\n",
    "        \"overlay_type\": \"grayscale\"\n",
    "        },\n",
    "        \"input_baselines\": [random_baseline.tolist()]\n",
    "      }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "      \"probability\": {\n",
    "        \"output_tensor_name\": \"dense_15/Softmax:0\"\n",
    "      }\n",
    "    },\n",
    "  \"framework\": \"tensorflow\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('explanation_metadata.json', 'w') as output_file:\n",
    "    json.dump(explanation_metadata, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp explanation_metadata.json $export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XRAI_VERSION = 'v_xrai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai-platform versions create $XRAI_VERSION \\\n",
    "--model $MODEL \\\n",
    "--origin $export_path \\\n",
    "--runtime-version 1.15 \\\n",
    "--framework TENSORFLOW \\\n",
    "--python-version 3.7 \\\n",
    "--machine-type n1-standard-4 \\\n",
    "--explanation-method xrai \\\n",
    "--num-integral-steps 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrai_response = predict_json('ambient-depth-287712', MODEL, instances, XRAI_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "classes = {0:'normal',1:'symptoms'}\n",
    "# Note: change the `ig_response` variable below if you didn't deploy an IG model\n",
    "for i,val in enumerate(xrai_response['explanations']):\n",
    "    class_name = classes[val['attributions_by_label'][0]['label_index']]\n",
    "    confidence_score = str(round(val['attributions_by_label'][0]['example_score'] * 100, 3)) + '%'\n",
    "    print('Predicted class: ' + str(class_name) + '\\n' + 'Confidence score: ' + confidence_score)\n",
    "    \n",
    "    img = instances[i]['conv2d_input'][0]['b64']\n",
    "    im = BytesIO(base64.b64decode(img))\n",
    "    i = mpimg.imread(im, format='JPG')\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "for idx, face in enumerate(xrai_response['explanations']):\n",
    "    predicted_face = classes[face['attributions_by_label'][0]['label_index']]\n",
    "    confidence = face['attributions_by_label'][0]['example_score']\n",
    "    print('Predicted face: ', predicted_face)\n",
    "    b64str = face['attributions_by_label'][0]['attributions']['data']['b64_jpeg']\n",
    "    i = base64.b64decode(b64str)\n",
    "    i = io.BytesIO(i)\n",
    "    i = mpimg.imread(i, format='JPG')\n",
    "\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,val in enumerate(xrai_response['explanations']):\n",
    "    baseline_score = val['attributions_by_label'][0]['baseline_score']\n",
    "    predicted_score = val['attributions_by_label'][0]['example_score']\n",
    "    print('Baseline score: ', baseline_score) \n",
    "    print('Predicted score: ', predicted_score)\n",
    "    print('Predicted - Baseline: ', predicted_score - baseline_score, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test_img = PIL.Image.fromarray((random_baseline * 255).astype('uint8'))\n",
    "buffer = BytesIO()\n",
    "rand_test_img.save(buffer, format=\"BMP\")\n",
    "new_image_string = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Preview it\n",
    "plt.imshow(rand_test_img)\n",
    "# Save the image to a variable in the format our model is expecting\n",
    "sanity_check_img = {'conv2d_input': [{'b64': new_image_string}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_resp = predict_json('ambient-depth-287712', MODEL, sanity_check_img, XRAI_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_img = base64.b64decode(sanity_check_resp['explanations'][0]['attributions_by_label'][0]['attributions']['data']['b64_jpeg'])\n",
    "sanity_check_img = io.BytesIO(sanity_check_img)\n",
    "sanity_check_img = mpimg.imread(sanity_check_img, format='JPG')\n",
    "\n",
    "plt.imshow(sanity_check_img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score = sanity_check_resp['explanations'][0]['attributions_by_label'][0]['baseline_score']\n",
    "example_score = sanity_check_resp['explanations'][0]['attributions_by_label'][0]['example_score']\n",
    "\n",
    "print(abs(baseline_score - example_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Parameter Setting for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_metadata = {\n",
    "    \"inputs\": {\n",
    "      \"data\": {\n",
    "        \"input_tensor_name\": \"vggface_vgg16_input:0\",\n",
    "        \"modality\": \"image\",\n",
    "        \"visualization\": {\n",
    "        \"type\": \"Outlines\", # Can also use \"pixels\"\n",
    "        \"polarity\": \"negative\",\n",
    "        \"clip_below_percentile\": 55,\n",
    "        \"clip_above_percentile\": 99.9,\n",
    "        \"color_map\": \"pink_green\",\n",
    "        \"overlay_type\": \"mask_black\"\n",
    "        },\n",
    "        \"input_baselines\": [random_baseline.tolist()]\n",
    "      }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "      \"probability\": {\n",
    "        \"output_tensor_name\": \"dense_15/Softmax:0\"\n",
    "      }\n",
    "    },\n",
    "  \"framework\": \"tensorflow\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('explanation_metadata.json', 'w') as output_file:\n",
    "    json.dump(explanation_metadata, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp explanation_metadata.json $export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_VERSION = 'v_ig_parameter1'\n",
    "! gcloud ai-platform versions delete $IG_VERSION --quiet --model $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai-platform versions create $IG_VERSION \\\n",
    "--model $MODEL \\\n",
    "--origin $export_path \\\n",
    "--runtime-version 1.15 \\\n",
    "--framework TENSORFLOW \\\n",
    "--python-version 3.7 \\\n",
    "--machine-type n1-standard-4 \\\n",
    "--explanation-method integrated-gradients \\\n",
    "--num-integral-steps 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform versions describe $IG_VERSION --model $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = []\n",
    "path = 'faces2/symptoms/'+str(1700)+'_symptoms.jpg'\n",
    "test_filenames.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "import base64\n",
    "import matplotlib.image as mpimg\n",
    "import googleapiclient\n",
    "for i in test_filenames:\n",
    "    with open(i,'rb') as img:\n",
    "        b64str = base64.b64encode(img.read()).decode('utf-8')\n",
    "        instances.append({'conv2d_input': [{'b64':b64str}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_response = predict_json('ambient-depth-287712', MODEL, instances, IG_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "classes = {0:'normal',1:'symptoms'}\n",
    "# Note: change the `ig_response` variable below if you didn't deploy an IG model\n",
    "for i,val in enumerate(ig_response['explanations']):\n",
    "    class_name = classes[val['attributions_by_label'][0]['label_index']]\n",
    "    confidence_score = str(round(val['attributions_by_label'][0]['example_score'] * 100, 3)) + '%'\n",
    "    print('Predicted class: ' + str(class_name) + '\\n' + 'Confidence score: ' + confidence_score)\n",
    "    \n",
    "    img = instances[i]['conv2d_input'][0]['b64']\n",
    "    im = BytesIO(base64.b64decode(img))\n",
    "    i = mpimg.imread(im, format='JPG')\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "classes = {0:'normal',1:'symptoms'}\n",
    "for idx, face in enumerate(ig_response['explanations']):\n",
    "    predicted_face = classes[face['attributions_by_label'][0]['label_index']]\n",
    "    confidence = face['attributions_by_label'][0]['example_score']\n",
    "    print('Predicted face: ', predicted_face)\n",
    "    b64str = face['attributions_by_label'][0]['attributions']['data']['b64_jpeg']\n",
    "    i = base64.b64decode(b64str)\n",
    "    i = io.BytesIO(i)\n",
    "    i = mpimg.imread(i, format='JPG')\n",
    "\n",
    "    plt.imshow(i, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,val in enumerate(ig_response['explanations']):\n",
    "    baseline_score = val['attributions_by_label'][0]['baseline_score']\n",
    "    predicted_score = val['attributions_by_label'][0]['example_score']\n",
    "    print('Baseline score: ', baseline_score) \n",
    "    print('Predicted score: ', predicted_score)\n",
    "    print('Predicted - Baseline: ', predicted_score - baseline_score, '\\n')\n",
    "    approx_error = val['attributions_by_label'][0]['approx_error']\n",
    "    print('Approximate error: ',approx_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
